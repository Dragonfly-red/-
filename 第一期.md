# 书生浦语大模型2.0

### 一：提供不同尺寸和类型的模型，支持多语言和多模态

```markdown
7B：为轻量级的研究和应用提供了一个轻便但性能不俗的模型
20B：模型的综合能力更为强劲，可以有效的支持更加复杂的实用场景
	base: InternLM2-Base,一个高质量的基座模型，有很高的可玩性，可以基于这个base模型塑造你个更适合需求任务的模型。
	LM2：InternLM2，就是在base模型的基础上进行了强化，可以使用LM作为通用任务的预训练模型，对模型针对下游任务做微调来适应更好的任务，达到更好的性能。
	LM2-Chat： InternLM2-Chat，在八色的基础上经过了SFT和RLHF，主要在对话交互上进行了优化。
```

新一代的数据清洗过滤技术（语言建模）

1.多维度数据价值评估

2.高质量雨量驱动的数据富集

3.有针对性的数据补齐

```
采用更少的语料达到更好的效果，用和上一代同样大小的语料可以达到更好的性能
```

### 二：亮点

```markdown
1.超长的上下文（支持20万token）
2.综合性能全面提升（推理，数学，代码，在充电评测上比肩ChatGPT）
3.优秀的对话和创作体验（精准指令跟随）
4.工具调用能力整体升级（支持工具多轮调用）
5.突出的数据能力和使用的数据分析功能（强大的内生计算能力）
```

### 三：从模型到应用

```markdown
看不同的开源模型在经典的评测集上的表现如何，更具自己的业务场景选择一个或者几个模型来考虑。然后考虑业务场景是否复杂，根据算力情况选择是微调部分参数还是全参数进行微调。看业务本身是否需要环境交互，看是否构建一个智能体去进行模型评测和模型部署
```

全链条的开源开放体系：

```markdown
1.数据： 书生·万卷CC  2TB数据，文本，图像，视频 事件跨度长来源丰富多样，安全密度高
2.预训练： 并行训练，极致的优化，速度达到3600tokens/sec/hpu
3.微调：支持全残数微调，支持LoRA等低成本的微调
4.评测： 中立全面的评测榜单 有100套评测集，50万道题目
5.部署: 全链路部署，性能领先，每秒生成2000+ tokens
6.应用：支持多种智能体。支持代码解释等多种工具
```

